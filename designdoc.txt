Options Forecast & Backtest — Design Document (Codex-Ready)

Purpose: unambiguous, token-friendly specification for code generation.
Style: short identifiers, explicit schemas, deterministic choices, minimal ambiguity.

0. Project Summary

Name: options-forecast-backtest

Goal: forecast option returns with ML, then backtest options strategies over historical data with realistic execution, costs, and risk controls.

Constraints: deterministic pipelines, idempotent runs, reproducible models, modular strategies, cloud-ready.

1. Scope

In:

Data ingestion: equities + options chains + greeks + IV.

Feature engineering: returns, technicals, greeks transforms, calendar features.

ML models: PyTorch (LSTM/GRU), tree models (XGBoost/LightGBM).

Forecast tasks: regression (y = Δoption_mid_%) and classification (y↑/y↓).

Backtester: event-driven, portfolio-aware, multi-strategy, daily/EOD.

Metrics: hit rate, ROC/AUC, MSE/MAE, Sharpe, Sortino, max drawdown, turnover, slippage cost.

Dashboard: Streamlit.

API: FastAPI for predictions, backtests, artifacts.

Storage: MongoDB (metadata), S3 (parquet + models), Redis (cache).

Experiment tracking: MLflow.

Scheduling: Airflow (or Prefect).

Out:

Live brokerage execution.

HFT intraday microstructure.

2. Non-Goals

No proprietary data connectors.

No sub-second execution.

No margin/PM modeling beyond delta-based approximations.

3. Architecture
client (Streamlit) ──> FastAPI (inference, backtest) ──> services
  |                                             |
  └──> S3 (data, models, reports) <── pipelines ┘
           ↑        ↑
       Airflow   MLflow
           ↑        ↑
   Ingestion -> Featurize -> Train -> Validate -> Register -> Serve


Services:

api: FastAPI app.

worker: Celery for async backtests + training.

scheduler: Airflow for DAGs.

db: MongoDB Atlas (collections described below).

cache: Redis.

4. Data Model
4.1 Storage

S3 layout:

s3://ofb/raw/{symbol}/{date}/[equity.parquet|options.parquet]

s3://ofb/processed/{symbol}/{date}/features.parquet

s3://ofb/models/{model_name}/{run_id}/[state_dict.pt|params.json]

s3://ofb/reports/{run_id}/[metrics.json|plots/*.png]

File formats: parquet (columnar, float32 where possible), UTC timestamps ISO-8601.

4.2 MongoDB Collections (schemas)

symbols

{ _id, symbol:str, exchange:str, is_active:bool, meta:{} }

ingestions

{ _id, symbol, start_date, end_date, rows:int, src:str, status:str, created_at, duration_s:float }

features

{ _id, symbol, date, n_rows:int, version:str, hash:str, stored_uri:str }

models

{ _id, name:str, framework:str, task:str, params:{}, created_at }

experiments

{ _id, model_name, run_id, data_version, feature_version, target:str, cv_scheme:str, metrics:{}, artifacts:{}, created_at }

predictions

{ _id, run_id, symbol, date, horizon:str, n:int, stored_uri:str }

backtests

{ _id, config_hash, run_id, strategy:str, symbol, start_date, end_date, metrics:{}, plots_uri:str, trades_uri:str, created_at }

reports

{ _id, run_id, type:str, uri:str, created_at }

All documents include created_at (UTC), tags:[str] optional.

5. Pipelines
5.1 Ingestion

Inputs: symbol list, date range.

Sources: Yahoo Finance (yfinance) baseline. Optional polygon/alpha vantage adapters.

Outputs:

equity.parquet: cols [ts, open, high, low, close, adj_close, volume].

options.parquet: cols [ts, expiry, type{C/P}, strike, bid, ask, mid, iv, delta, gamma, theta, vega, oi, volume].

Constraints:

Align equity and options to EOD (or chosen bar), drop illiquid options by thresholds (min_oi, min_volume).

Compute mid = (bid+ask)/2 with NA guard.

5.2 Feature Engineering

Join equity + options by [ts, expiry, strike, type].

Targets:

Regression: y = pct_change(mid, horizon_k_days).

Classification: y_bin = 1 if y > thresh else 0.

Features (examples):

r1 = close.pct_change(1), r5, r21.

iv, iv_rank_252, iv_pctile_252.

greeks: delta, gamma, theta, vega.

technicals on underlying: rsi_14, macd_12_26, bb_pct_20.

time: dow, dom, expiry_dte.

moneyness: (underlying - strike)/underlying.

liquidity: spread = (ask-bid)/mid, oi, volume.

Normalization:

Train split fit scalers; save scaler.pkl with feature list and dtypes.

Output: features.parquet + schema.json + hash.

5.3 Train

Split: time-based (walk-forward) or expanding window.

CV: rolling windows K=5.

Models:

torch_lstm: sequence length L=32, features F, target y.

xgb_reg or xgb_clf.

Loss:

Regression: MSE; auxiliary pinball for quantiles (optional).

Classification: BCE.

Optimizer: Adam, lr schedule cosine, early stop on val.

Tracking: MLflow params + metrics + artifacts (confusion, SHAP, feature importance).

Registry: models + upload state to S3.

5.4 Inference

Batch predict on new dates:

Load latest model_name + run_id.

Fetch latest features, apply scaler, predict score.

Store predictions parquet: [ts, symbol, option_key, score, yhat, p_up].

6. Backtesting Engine
6.1 Core Concepts

Clock: iterates trading days D.

Universe: filtered options per rules (e.g., min_dte, max_spread).

Signal: mapping (option_key->score).

Allocator: position sizing function.

Broker Sim: fills with slippage/commissions.

Portfolio: tracks cash, positions, P&L, risk limits.

6.2 Config (YAML)
name: "bt_straddle_topk"
symbol: "AAPL"
start_date: "2018-01-01"
end_date: "2024-12-31"
data:
  feature_version: "v1.0"
  prediction_run: "run_2025_10_27_01"
universe:
  dte_min: 7
  dte_max: 30
  type: ["C","P"]
  moneyness_min: -0.05
  moneyness_max: 0.05
  min_oi: 200
  max_spread_pct: 0.05
signal:
  select_top_k: 10
  side: "buy"            # buy or sell depending on strategy
execution:
  slippage_bps: 15
  commission_per_contract: 0.65
  price: "mid"           # or bid/ask
risk:
  max_gross_notional: 100000
  max_position_per_option: 10
  stop_loss_pct: 0.3
  take_profit_pct: 0.5
rebalance:
  frequency: "daily"
  exit_after_days: 10
reports:
  save_trades: true
  save_daily_equity: true

6.3 Strategy Modules

straddle_buy: buy ATM call+put at DTE window when predicted variance high (proxy via |score| or iv signal).

credit_spread_sell: sell OTM vertical when p_up or p_down >= threshold + favorable greeks.

covered_call: long stock + short call when p_up modest and iv elevated.

6.4 Pricing / Fills

Default fill: mid ± slippage_bps.

Expiry handling: cash-settle to option intrinsic; assignment simulation simplified: exercise ITM at expiry.

Early exit: stop/take using mid mark.

6.5 Metrics

Trade‐level: win_rate, avg_win, avg_loss, payoff_ratio, holding_days.

Equity‐level: CAGR, vol, Sharpe, Sortino, max_dd, calmar, turnover, exposure.

Risk: delta exposure time-series; P99 drawdown length.

6.6 Output Artifacts

trades.parquet: [date, option_key, side, qty, entry, exit, pnl, fees]

equity.parquet: [date, nav]

metrics.json

Plots: equity curve, drawdown, rolling Sharpe, exposure.

7. APIs (FastAPI)

Base: /api/v1

7.1 Health

GET /health → {status:"ok", time:utc}

7.2 Predictions

POST /predict

Req: {symbol:str, date:str, horizon:str, model_name:str?}

Res: {run_id, n, uri}

GET /predictions/{run_id}

Res: list of records or signed S3 link.

7.3 Backtests

POST /backtests

Req: config_yaml:str | config:object

Res: {bt_id, status:"queued"}

GET /backtests/{bt_id}

Res: {status, metrics, trades_uri, equity_uri, plots_uri}

7.4 Models

GET /models → list names + latest runs

GET /models/{name}/latest → {run_id, metrics}

7.5 Error Contract

Error JSON: {error_code:str, message:str, details?:{}}

Codes: BAD_REQUEST, NOT_FOUND, CONFLICT, INTERNAL.

8. Streamlit Dashboard

Pages:

Overview: run status, latest models, dataset versions.

Predictions: select symbol/date, view top-K options with scores.

Backtest: form to build config; run; show metrics + plots.

Reports: download artifacts.

Components:

Equity curve, drawdown, rolling Sharpe (Matplotlib/Plotly).

Tables: trades, top signals, feature importances.

9. ML Details
9.1 Datasets

Sequence dataset:

X: [batch, time=L, features=F]

y: [batch] (reg) or [batch, 1] (clf)

Collation: pad not used; fixed L.

9.2 Model Definitions

TorchLSTM

input_size=F

hidden=128

layers=2

dropout=0.2

head: MLP [128->64->1] for regression or sigmoid for classification.

XGBRegressor / XGBClassifier

Params stored in params.json; feature list saved.

9.3 Training Loop (pseudo)
for epoch in range(E):
  for batch in loader:
    yhat = model(x)
    loss = criterion(yhat, y)
    loss.backward()
    clip_grad_norm_(model.parameters(), 1.0)
    opt.step(); opt.zero_grad()
  val = eval(model)
  if early_stop(val): break
save(state_dict, scaler, feature_list)
log_mlflow(params, metrics, artifacts)

9.4 Explainability

Tree models: gain/cover importance + SHAP (tree explainer).

NN: feature ablation report.

10. Reproducibility

Set seeds {python, numpy, torch}.

Pin requirements with hashes.

DVC stages for ingest, features, train, predict.

MLflow run IDs used across predictions/backtests.

All timestamps UTC; date inputs YYYY-MM-DD.

11. Configuration

.env (example):

ENV=dev
MONGO_URI=mongodb+srv://...
REDIS_URL=redis://redis:6379/0
S3_BUCKET=ofb
AWS_REGION=us-east-1
MLFLOW_TRACKING_URI=http://mlflow:5000
SECRET_KEY=<32+ chars>


settings.py: Pydantic BaseSettings reading .env.

12. CI/CD

GitHub Actions:

lint: ruff + mypy.

test: pytest + coverage.

build: docker images api, worker, scheduler, streamlit.

push: to registry on main.

On deploy:

run DB migrations (if any indexes).

smoke test /health.

13. docker-compose.yml (minimal dev)
version: "3.9"
services:
  api:
    build: ./api
    env_file: .env
    ports: ["8000:8000"]
    depends_on: [redis, mlflow]
  worker:
    build: ./worker
    env_file: .env
    depends_on: [redis]
  streamlit:
    build: ./dashboard
    env_file: .env
    ports: ["8501:8501"]
    depends_on: [api]
  redis:
    image: redis:7
    ports: ["6379:6379"]
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlruns
    volumes: ["./.mlruns:/mlruns"]
    ports: ["5000:5000"]

14. Repository Layout
options-forecast-backtest/
├── api/
│   ├── main.py
│   ├── routers/ [predict.py, backtest.py, models.py]
│   ├── services/ [inference.py, backtester.py]
│   ├── core/ [settings.py, logging.py, errors.py]
│   └── schemas/ [io.py]
├── pipelines/
│   ├── ingest_yf.py
│   ├── features.py
│   ├── train_torch.py
│   ├── train_xgb.py
│   ├── predict.py
│   └── dvc.yaml
├── backtest/
│   ├── engine.py
│   ├── broker.py
│   ├── metrics.py
│   └── strategies/ [straddle.py, credit_spread.py, covered_call.py]
├── ml/
│   ├── datasets.py
│   ├── models/ [lstm.py, heads.py]
│   └── utils/ [train.py, eval.py, seed.py]
├── dashboard/
│   ├── app.py
│   └── components/ [plots.py, tables.py]
├── common/
│   ├── io.py   # s3, parquet helpers
│   ├── db.py   # mongo helpers
│   ├── cache.py
│   ├── time.py
│   └── schema.py
├── tests/
│   ├── unit/
│   └── integration/
├── requirements.txt
├── docker-compose.yml
├── .env.example
└── README.md

15. Logging & Telemetry

Logger: structlog JSON lines.

Fields: ts, level, svc, run_id, symbol, stage, msg, extra.

Persist run summaries to Mongo experiments / backtests.

16. Indices / Performance

Mongo indices:

predictions: {run_id:1, symbol:1, date:1}

backtests: {strategy:1, symbol:1, start_date:1, end_date:1}

Parquet:

Partition by symbol and date for features/preds.

Use float32 dtypes where safe; categorical encodings for type.

17. Testing Plan

Unit:

feature transforms deterministic with fixed seed.

model forward shapes and training step.

pricing/fill math and fees.

Integration:

end-to-end ingest -> features -> train -> predict -> backtest on small fixture dataset.

Golden tests: lock expected metrics.json tolerances (± small eps).

18. Security

Secrets only in env vars; never in repo.

All external endpoints HTTPS.

Request validation via Pydantic schemas.

Basic auth or token for /backtests and /predict in prod.

19. Example FastAPI Schemas (Pydantic)
class PredictReq(BaseModel):
    symbol: str
    date: date
    horizon: Literal["1d","5d","10d"]
    model_name: str | None = None

class PredictRes(BaseModel):
    run_id: str
    n: int
    uri: AnyUrl

class BacktestReq(BaseModel):
    config_yaml: str

class BacktestRes(BaseModel):
    bt_id: str
    status: Literal["queued","running","done","error"]

20. Example Backtest Engine Pseudocode
def run_backtest(cfg):
  clock = TradingDays(cfg.start_date, cfg.end_date)
  pf = Portfolio(cfg.risk)
  for d in clock:
    uni = build_universe(d, cfg.universe)
    sig = load_predictions(cfg.signal.prediction_run, d, uni)
    orders = strategy_generate(cfg.strategy, sig, pf, cfg)
    fills = broker_sim_fill(orders, d, cfg.execution)
    pf.update(fills, mark_to_market(d))
    if exit_rules_triggered(...): pf.close_positions(...)
  metrics = compute_metrics(pf.equity_curve)
  save_artifacts(trades, equity, metrics)
  return metrics

21. Determinism & Seeds

SEED=1337 default.

Set seeds in:

Python: random.seed(SEED)

NumPy: np.random.seed(SEED)

Torch: torch.manual_seed(SEED), torch.use_deterministic_algorithms(True) (if supported).

22. Slippage & Fees

slippage_bps: applied to mid price; buy = mid + bps, sell = mid - bps.

commission_per_contract: added to each open/close leg.

Spread sanity check: if spread_pct > max_spread_pct, skip instrument.

23. Rollout Plan

Milestone M1: ingest + features + unit tests.

M2: XGB baseline model + CV + explainability.

M3: Backtester + straddle strategy + metrics.

M4: API + Streamlit + CI.

M5: Torch LSTM + Optuna tuning + RL (optional extension).

24. Requirements (base)
fastapi
uvicorn
pydantic
pandas
numpy
pyarrow
matplotlib
plotly
scikit-learn
xgboost
torch
optuna
mlflow
yfinance
boto3
pymongo
redis
celery
structlog
python-dotenv
streamlit

25. Makefile Targets (dev)
make setup        # install deps
make lint         # ruff + mypy
make test         # pytest
make ingest       # run pipelines/ingest_yf.py
make features     # run pipelines/features.py
make train        # run pipelines/train_xgb.py
make predict      # run pipelines/predict.py
make backtest     # run via API or CLI
make up           # docker-compose up

26. Acceptance Criteria

Run end-to-end on AAPL 2018-2024: produce predictions + backtest artifacts deterministically.

Baseline strategy achieves Sharpe > 0.8 (toy setting) on sample config with fixed seed (illustrative, not a promise of real performance).

API contract passes schema validation; dashboard loads and renders equity/trades.

27. Tokenization Notes (for Codex)

Prefer short, snake_case identifiers.

Keep function signatures ≤ 5 params; otherwise pass a cfg object.

Avoid ambiguous names; always suffix: _uri, _id, _pct, _bps, _dte.

Always include type hints.

Keep I/O boundaries explicit: pure transforms vs side-effects.

One module = one responsibility.